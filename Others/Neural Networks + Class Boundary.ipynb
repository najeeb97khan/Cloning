{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_random(orig_data, feature_names, data_size):\n",
    "    '''\n",
    "    Input: Data, Feature Names, Size of Random Data\n",
    "    Output: Random Data\n",
    "    \n",
    "    Generates random dataset of size data_size\n",
    "    Random dataset is generated from normal\n",
    "    distribution with specified high and low values\n",
    "    '''\n",
    "    \n",
    "    df = {}\n",
    "    for i in range(len(feature_names)):\n",
    "        low = np.min(orig_data[:, i])\n",
    "        high = np.max(orig_data[:, i])\n",
    "        df[feature_names[i]] = np.random.uniform(low=low, high=high, size=data_size)\n",
    "    random_dataset = pd.DataFrame(data=df, columns=feature_names)\n",
    "    \n",
    "    return random_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constructNetwork(num_features, num_classes, num_hidden, X, y, X_random=None, NUM_EPOCHS=10, SKIP_STEP=5, LEARNING_RATE=1e-4):\n",
    "    \n",
    "    with tf.variable_scope(\"Placeholder\") as scope:\n",
    "        input_tensor = tf.placeholder(dtype=tf.float32, shape=[None, num_features], name=\"input\")\n",
    "        label = tf.placeholder(dtype=tf.float32, shape=[None, num_classes], name=\"label\")\n",
    "    \n",
    "    with tf.variable_scope(\"hidden_layer\") as scope:\n",
    "        w = tf.get_variable(dtype=tf.float32, shape=[num_features, num_hidden], initializer=tf.random_normal_initializer(), name=\"weights\")\n",
    "        b = tf.get_variable(dtype=tf.float32, shape=[num_hidden], initializer=tf.random_normal_initializer(), name=\"biases\")\n",
    "        out = tf.nn.relu(tf.matmul(input_tensor, w) + b)\n",
    "        \n",
    "    with tf.variable_scope(\"output_layer\") as scope:\n",
    "        w = tf.get_variable(dtype=tf.float32, shape=[num_hidden, num_classes], initializer=tf.random_normal_initializer(), name=\"weights\")\n",
    "        b = tf.get_variable(dtype=tf.float32, shape=[num_classes], initializer=tf.random_normal_initializer(), name=\"biases\")\n",
    "        softmax = tf.nn.softmax(tf.matmul(out, w) + b)\n",
    "        \n",
    "    with tf.variable_scope(\"loss\") as scope:\n",
    "        loss = tf.reduce_mean(-tf.reduce_sum(label*tf.log(tf.clip_by_value(softmax,1e-10,1.0)), reduction_indices=[1]))\n",
    "        \n",
    "    with tf.variable_scope(\"optimizer\") as scope:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(loss)\n",
    "    \n",
    "    with tf.variable_scope(\"accuracy\") as scope:\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.arg_max(softmax, 1), tf.arg_max(label, 1)), dtype=tf.float32))\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "    \n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "    \n",
    "        for i in range(1, NUM_EPOCHS+1):\n",
    "        \n",
    "            _, l, acc = sess.run([optimizer, loss, accuracy], feed_dict={input_tensor:X, label:y})\n",
    "        \n",
    "            if i % SKIP_STEP == 0:\n",
    "                \n",
    "                print 'Epoch: {}\\n Loss: {}\\t Accuracy: {}'.format(i, l, acc)\n",
    "            \n",
    "        try:\n",
    "            y_random = sess.run([softmax], feed_dict={input_tensor: X_random})\n",
    "            return y_random\n",
    "        except:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancer Dataset (30 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "## Gettting the data\n",
    "data = datasets.load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "feature_names = data.feature_names\n",
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 2)\n"
     ]
    }
   ],
   "source": [
    "y = pd.get_dummies(y).values\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.11890932377e-16 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(X)\n",
    "print np.mean(X), np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 30)\n"
     ]
    }
   ],
   "source": [
    "X_random = generate_random(X, feature_names, data_size=1000).values\n",
    "print X_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000\n",
      " Loss: 0.715131878853\t Accuracy: 0.931458711624\n",
      "Epoch: 2000\n",
      " Loss: 0.235907152295\t Accuracy: 0.978910386562\n",
      "Epoch: 3000\n",
      " Loss: 0.187432423234\t Accuracy: 0.985940217972\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "y_random = constructNetwork(30, 2, 128, X, y, X_random, NUM_EPOCHS=3000, SKIP_STEP=1000, LEARNING_RATE=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000\n",
      " Loss: 0.815012216568\t Accuracy: 0.966000020504\n",
      "Epoch: 2000\n",
      " Loss: 0.820866465569\t Accuracy: 0.961000025272\n",
      "Epoch: 3000\n",
      " Loss: 0.809443116188\t Accuracy: 0.964999973774\n",
      "Epoch: 4000\n",
      " Loss: 0.534660756588\t Accuracy: 0.977999985218\n",
      "Epoch: 5000\n",
      " Loss: 0.53012150526\t Accuracy: 0.976999998093\n",
      "Epoch: 6000\n",
      " Loss: 0.531763911247\t Accuracy: 0.977999985218\n",
      "Epoch: 7000\n",
      " Loss: 0.531323313713\t Accuracy: 0.976000010967\n",
      "Epoch: 8000\n",
      " Loss: 0.527147769928\t Accuracy: 0.976000010967\n",
      "Epoch: 9000\n",
      " Loss: 0.536090373993\t Accuracy: 0.975000023842\n",
      "Epoch: 10000\n",
      " Loss: 0.525169551373\t Accuracy: 0.976999998093\n",
      "Epoch: 11000\n",
      " Loss: 0.524739384651\t Accuracy: 0.976999998093\n",
      "Epoch: 12000\n",
      " Loss: 0.52328813076\t Accuracy: 0.976000010967\n",
      "Epoch: 13000\n",
      " Loss: 0.521253705025\t Accuracy: 0.976999998093\n",
      "Epoch: 14000\n",
      " Loss: 0.522794902325\t Accuracy: 0.975000023842\n",
      "Epoch: 15000\n",
      " Loss: 0.368185311556\t Accuracy: 0.985000014305\n",
      "Epoch: 16000\n",
      " Loss: 0.299120634794\t Accuracy: 0.989000022411\n",
      "Epoch: 17000\n",
      " Loss: 0.299335926771\t Accuracy: 0.987999975681\n",
      "Epoch: 18000\n",
      " Loss: 0.299936413765\t Accuracy: 0.986999988556\n",
      "Epoch: 19000\n",
      " Loss: 0.294460326433\t Accuracy: 0.986999988556\n",
      "Epoch: 20000\n",
      " Loss: 0.29527503252\t Accuracy: 0.986999988556\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "preds = constructNetwork(30, 2, 128, X_random, y_random[0], X, NUM_EPOCHS=20000, SKIP_STEP=1000, LEARNING_RATE=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on original dataset:  0.919156414763\n"
     ]
    }
   ],
   "source": [
    "print 'Accuracy on original dataset: ', np.mean(np.equal(np.argmax(preds[0], 1), np.argmax(y, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905096660808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_random, np.argmax(y_random[0], 1))\n",
    "print model.score(X, np.argmax(y, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is nice! o_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
